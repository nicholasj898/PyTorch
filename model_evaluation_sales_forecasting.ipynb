{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPbWmJL6ajT_",
    "outputId": "4f930481-0c0f-4f30-c5be-16890a86c17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:05<00:00, 33.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# CIFAR-100 dataset loading with transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load training and test sets\n",
    "train_set = dsets.CIFAR100(root='./data', train=True, transform=transform, download=True)\n",
    "test_set = dsets.CIFAR100(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HCdRycRfa6co"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "subtrain_set, val_set = torch.utils.data.random_split(train_set, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(subtrain_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f3k0fE4MbIse"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 512)\n",
    "        self.fc2 = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ReLU()(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GxbvUxAsbMGv"
   },
   "outputs": [],
   "source": [
    "# Model 1: criterion, and optimizer\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ve538nYEbgr_",
    "outputId": "6d8922ad-5d60-4984-b1e0-71ede2c6c1e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost = 3.677025\n",
      "Validation Accuracy: 22.83%\n",
      "Epoch: 2, cost = 2.890987\n",
      "Validation Accuracy: 31.00%\n",
      "Epoch: 3, cost = 2.499290\n",
      "Validation Accuracy: 34.95%\n",
      "Epoch: 4, cost = 2.197762\n",
      "Validation Accuracy: 38.00%\n",
      "Epoch: 5, cost = 1.947838\n",
      "Validation Accuracy: 38.86%\n",
      "Epoch: 6, cost = 1.715972\n",
      "Validation Accuracy: 40.06%\n",
      "Epoch: 7, cost = 1.494463\n",
      "Validation Accuracy: 40.11%\n",
      "Epoch: 8, cost = 1.279967\n",
      "Validation Accuracy: 39.84%\n",
      "Epoch: 9, cost = 1.086881\n",
      "Validation Accuracy: 38.19%\n",
      "Epoch: 10, cost = 0.906014\n",
      "Validation Accuracy: 38.65%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(model(X), Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, cost = {avg_cost:.6f}')\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_Y in val_loader:\n",
    "            val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_Y.size(0)\n",
    "            correct += (predicted == val_Y).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "    model.train()  # Setting the model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mk6FcXNVblTf",
    "outputId": "1b8b313f-e437-4f2b-a7f4-4b1423270e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 39.05%\n"
     ]
    }
   ],
   "source": [
    "# Test model evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for test_X, test_Y in test_loader:\n",
    "        test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "        outputs = model(test_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += test_Y.size(0)\n",
    "        correct += (predicted == test_Y).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uPCtsmVBgTQ_"
   },
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(8 * 8 * 128, 256)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ReLU()(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hXRo7YAdgeVn"
   },
   "outputs": [],
   "source": [
    "# Model 2: criterion, and optimizer\n",
    "model = CNN2().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz5KqlaLghd3",
    "outputId": "0159d8d2-8f14-4cc8-a78e-2d1b5e8b6e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost = 8.416035\n",
      "Validation Accuracy: 0.93%\n",
      "Epoch: 2, cost = 4.621924\n",
      "Validation Accuracy: 0.97%\n",
      "Epoch: 3, cost = 4.621541\n",
      "Validation Accuracy: 1.03%\n",
      "Epoch: 4, cost = 4.621964\n",
      "Validation Accuracy: 0.99%\n",
      "Epoch: 5, cost = 4.621321\n",
      "Validation Accuracy: 1.03%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(model(X), Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, cost = {avg_cost:.6f}')\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_Y in val_loader:\n",
    "            val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_Y.size(0)\n",
    "            correct += (predicted == val_Y).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "    model.train()  # Setting the model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0crRqSs1g4cX",
    "outputId": "9b423dfc-5167-48e9-aa90-1eaa2068027f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.00%\n"
     ]
    }
   ],
   "source": [
    "# Test model evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for test_X, test_Y in test_loader:\n",
    "        test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "        outputs = model(test_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += test_Y.size(0)\n",
    "        correct += (predicted == test_Y).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "prd2M0xSg82P"
   },
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(nn.LeakyReLU(0.1)(self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yhggkzrgnmCn"
   },
   "outputs": [],
   "source": [
    "# Model 3: criterion, and optimizer\n",
    "model = CNN3().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTpDM9jenuw3",
    "outputId": "f8f798c5-660a-4848-8a54-37f00dbe3bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost = 43739.777344\n",
      "Validation Accuracy: 2.42%\n",
      "Epoch: 2, cost = 502.512054\n",
      "Validation Accuracy: 2.98%\n",
      "Epoch: 3, cost = 239.197739\n",
      "Validation Accuracy: 4.18%\n",
      "Epoch: 4, cost = 67.072227\n",
      "Validation Accuracy: 3.77%\n",
      "Epoch: 5, cost = 45.390640\n",
      "Validation Accuracy: 4.26%\n",
      "Epoch: 6, cost = 188396240.000000\n",
      "Validation Accuracy: 1.25%\n",
      "Epoch: 7, cost = 15689974.000000\n",
      "Validation Accuracy: 3.67%\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(model(X), Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, cost = {avg_cost:.6f}')\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_Y in val_loader:\n",
    "            val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_Y.size(0)\n",
    "            correct += (predicted == val_Y).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "    model.train()  # Setting the model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8UTLco3n5ov",
    "outputId": "a59156db-aa4c-42fd-ec2a-de6b54ab4d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 2.01%\n"
     ]
    }
   ],
   "source": [
    "# Test model evaluation\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for test_X, test_Y in test_loader:\n",
    "        test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "        outputs = model(test_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += test_Y.size(0)\n",
    "        correct += (predicted == test_Y).sum().item()\n",
    "\n",
    "test_acc = 100 * correct / total\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fq21fjdmrheA"
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_X, test_Y in test_loader:\n",
    "            test_X, test_Y = test_X.to(device), test_Y.to(device)\n",
    "            outputs = model(test_X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += test_Y.size(0)\n",
    "            correct += (predicted == test_Y).sum().item()\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "27ZvXR1jr_Vg"
   },
   "outputs": [],
   "source": [
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 256)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.dropout(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "l4r8-dwMvUAw"
   },
   "outputs": [],
   "source": [
    "# Model 4: criterion, and optimizer\n",
    "model = CNN4().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTRobAX1vbyg",
    "outputId": "efa59bf7-5aa1-41b2-ae95-9a77fab0576c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost = 1432.541016\n",
      "Validation Accuracy: 1.06%\n",
      "Epoch: 2, cost = 206.046295\n",
      "Validation Accuracy: 0.99%\n",
      "Epoch: 3, cost = 149.994690\n",
      "Validation Accuracy: 1.05%\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(model(X), Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, cost = {avg_cost:.6f}')\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_Y in val_loader:\n",
    "            val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_Y.size(0)\n",
    "            correct += (predicted == val_Y).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "    model.train()  # Setting the model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XIHYFCaTvhOY"
   },
   "outputs": [],
   "source": [
    "class CNN5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4 * 4 * 256, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ELU()(self.fc1(out))\n",
    "        out = nn.ELU()(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "113YnLlzypFY"
   },
   "outputs": [],
   "source": [
    "# Model 5: criterion, and optimizer\n",
    "model = CNN4().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sHZR5OHRyutw",
    "outputId": "72c33eee-1f02-4938-a032-89d0eb2e63e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost = 206849.937500\n",
      "Validation Accuracy: 1.01%\n",
      "Epoch: 2, cost = 12197.692383\n",
      "Validation Accuracy: 0.95%\n",
      "Epoch: 3, cost = 11883.354492\n",
      "Validation Accuracy: 0.79%\n",
      "Epoch: 4, cost = 13132.405273\n",
      "Validation Accuracy: 0.93%\n",
      "Epoch: 5, cost = 12136.412109\n",
      "Validation Accuracy: 0.80%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(train_loader)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost = criterion(model(X), Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print(f'Epoch: {epoch + 1}, cost = {avg_cost:.6f}')\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for val_X, val_Y in val_loader:\n",
    "            val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "            val_outputs = model(val_X)\n",
    "            _, predicted = torch.max(val_outputs, 1)\n",
    "            total += val_Y.size(0)\n",
    "            correct += (predicted == val_Y).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "    print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "    model.train()  # Setting the model back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7RIHal2Xy0Lo"
   },
   "outputs": [],
   "source": [
    "# Use the entire training dataset (without splitting)\n",
    "full_train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qVp6Rsw630A5"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X, Y in train_loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "2VV0tZ5Q32q4"
   },
   "outputs": [],
   "source": [
    "model1 = CNN().to(device)\n",
    "model2 = CNN2().to(device)\n",
    "model3 = CNN3().to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Define optimizers\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.001)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBhAckrJ4McB",
    "outputId": "234ced9a-e37a-43e6-c281-21cb0b8e1fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Retrain\n",
      "Epoch [1/10], Loss: 3.5497\n",
      "Epoch [2/10], Loss: 2.7308\n",
      "Epoch [3/10], Loss: 2.3128\n",
      "Epoch [4/10], Loss: 2.0129\n",
      "Epoch [5/10], Loss: 1.7621\n",
      "Epoch [6/10], Loss: 1.5338\n",
      "Epoch [7/10], Loss: 1.3212\n",
      "Epoch [8/10], Loss: 1.1239\n",
      "Epoch [9/10], Loss: 0.9366\n",
      "Epoch [10/10], Loss: 0.7829\n",
      "\n",
      " Model 2 Retrain\n",
      "Epoch [1/10], Loss: 3.4140\n",
      "Epoch [2/10], Loss: 2.6029\n",
      "Epoch [3/10], Loss: 2.2070\n",
      "Epoch [4/10], Loss: 1.8949\n",
      "Epoch [5/10], Loss: 1.6143\n",
      "Epoch [6/10], Loss: 1.3476\n",
      "Epoch [7/10], Loss: 1.1028\n",
      "Epoch [8/10], Loss: 0.8768\n",
      "Epoch [9/10], Loss: 0.6836\n",
      "Epoch [10/10], Loss: 0.5279\n",
      "\n",
      " Model 3 Retrain\n",
      "Epoch [1/10], Loss: 3.5587\n",
      "Epoch [2/10], Loss: 2.7553\n",
      "Epoch [3/10], Loss: 2.3526\n",
      "Epoch [4/10], Loss: 2.0624\n",
      "Epoch [5/10], Loss: 1.8451\n",
      "Epoch [6/10], Loss: 1.6485\n",
      "Epoch [7/10], Loss: 1.4772\n",
      "Epoch [8/10], Loss: 1.3153\n",
      "Epoch [9/10], Loss: 1.1793\n",
      "Epoch [10/10], Loss: 1.0580\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1 Retrain\")\n",
    "train_model(model1, full_train_loader, optimizer1, criterion)\n",
    "\n",
    "print(\"\\n Model 2 Retrain\")\n",
    "train_model(model2, full_train_loader, optimizer2, criterion)\n",
    "\n",
    "print(\"\\n Model 3 Retrain\")\n",
    "train_model(model3, full_train_loader, optimizer3, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YXobmwPR4abY"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in test_loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            outputs = model(X)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += Y.size(0)\n",
    "            correct += (predicted == Y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbjuZtu-MDV6",
    "outputId": "a145dac2-13ae-4ad9-eda8-114e0e282f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Model 1 (CNN): 41.42%\n",
      "Test Accuracy of Model 2 (CNN2): 38.46%\n",
      "Test Accuracy of Model 3 (CNN3): 50.22%\n"
     ]
    }
   ],
   "source": [
    "test1 = evaluate_model(model1, test_loader)\n",
    "test2 = evaluate_model(model2, test_loader)\n",
    "test3 = evaluate_model(model3, test_loader)\n",
    "\n",
    "print(f\"Test Accuracy of Model 1 (CNN): {test1:.2f}%\")\n",
    "print(f\"Test Accuracy of Model 2 (CNN2): {test2:.2f}%\")\n",
    "print(f\"Test Accuracy of Model 3 (CNN3): {test3:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "CdKhSULsMPrp"
   },
   "outputs": [],
   "source": [
    "# Benchmarking:\n",
    "# These models achieved test accuracies of 41.42%, 38.46%, and 50.22%.\n",
    "# The top models on the CIFAR-100 leaderboard often exceed 80% accuracy,\n",
    "# but these use additional data and more complex architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqeWKC_aNg9K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
